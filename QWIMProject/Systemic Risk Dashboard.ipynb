{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n",
      "C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\pyfolio\\pos.py:27: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; mutltipliers will not be applied' +\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import riskfolio.Portfolio as pf\n",
    "\n",
    "\n",
    "import empyrical.stats as em\n",
    "import quantstats as qs\n",
    "import pyfolio as pyf\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "\n",
    "#Added by Ji Wu\n",
    "plt.style.use('fivethirtyeight')\n",
    "np.random.seed(777)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "yf.pdr_override()\n",
    "# pd.options.display.float_format = '{:.4%}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  16 of 16 completed\n"
     ]
    }
   ],
   "source": [
    "# Date range\n",
    "start =  '2000-01-03'  #POS'2000-01-03' #2001-01-11 \n",
    "end =   '2017-12-31' #POS'2017-01-31' #'2018-01-02' \n",
    "\n",
    "\n",
    "# Tickers of stocks - Inputted from dashboard\n",
    "stocks = ['BAC', 'C', 'SNV', 'STI', 'WFC', 'LNC', 'PGR', 'GL', 'GS',\n",
    "                  'SCHW', 'AXP', 'BEN', 'BLK', 'COF', 'MS']\n",
    "stocks.sort()\n",
    "\n",
    "\n",
    "#With SPY\n",
    "assets = stocks.copy()\n",
    "assets.append('SPY')\n",
    "\n",
    "   \n",
    "# Downloading data\n",
    "data = yf.download(assets, start = start, end = end)\n",
    "data = data.loc[:,('Adj Close', slice(None))]\n",
    "data.columns = assets\n",
    "\n",
    "\n",
    "# Calculating returns\n",
    "Return_Data = data.pct_change().dropna()\n",
    "# Return_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 1500\n",
    "num_portfolios = 2000\n",
    "month = 22\n",
    "# Return_Data[ticker_list]\n",
    "# ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate COSR weights\n",
    "def CoSR_weights(i,c, tickers):\n",
    "    index = i\n",
    "    port_CoSR_ratio = []\n",
    "    port_volatility = []\n",
    "    stock_weights = []\n",
    "    weights = []\n",
    "    stocks = tickers\n",
    "\n",
    "#     df = Return_Data[i:i+window]\n",
    "    \n",
    "    df_return_C = pd.DataFrame(columns = assets)\n",
    "    df = Return_Data[i:i+window].iloc[4:]\n",
    "    \n",
    "    a = 0\n",
    "    while a < len(df):\n",
    "        if qs.stats.comp(df[a:a+month]['SPY']) < c:\n",
    "            df_return_C = df_return_C.append(df[a:a+month])\n",
    "        a= a+month\n",
    "\n",
    "    #Filtering based on ticker_list\n",
    "    ticker_spy = tickers.copy()\n",
    "    ticker_spy.append('SPY')\n",
    "    df  = df_return_C[ticker_spy]\n",
    "    Y_SPY = pd.DataFrame(df['SPY'], columns = ['SPY'])\n",
    "    Y = df[stocks] \n",
    "    \n",
    "    \n",
    "    cov_matrix = Y.cov()\n",
    "    mean_returns = Y.mean()\n",
    "    mkt_returns = Y_SPY.SPY.mean()\n",
    "\n",
    "    for i in range(num_portfolios):\n",
    "        weights = np.random.random(len(stocks))\n",
    "        weights /= np.sum(weights)\n",
    "        mkt_returns = df['SPY'].mean()\n",
    "        returns = np.dot(weights, mean_returns)\n",
    "        volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        CoSR_ratio = (returns - mkt_returns)/volatility\n",
    "        port_CoSR_ratio.append(CoSR_ratio)\n",
    "        stock_weights.append(weights)\n",
    "        \n",
    "    weight = stock_weights[port_CoSR_ratio.index(max(port_CoSR_ratio))]\n",
    "\n",
    "    df = pd.DataFrame(data = weight, index = stocks).T\n",
    "  \n",
    "    #print(index+window+month + 1 )\n",
    "    #print(len(data)-(index+window+1))\n",
    "    if index+window+month + 1 < len(data):\n",
    "        newdf = pd.DataFrame(np.repeat(df.values,month,axis=0))\n",
    "        newdf.columns = df.columns\n",
    "        newdf['Date'] = data.index.values[index+window+1:index+window+month + 1]\n",
    "    else:\n",
    "        newdf = pd.DataFrame(np.repeat(df.values,len(data)-(index+window+1),axis=0))\n",
    "        newdf.columns = df.columns\n",
    "        newdf['Date'] = data.index.values[index+window+1:len(data)]\n",
    "    \n",
    "    newdf= newdf.set_index('Date')\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate SR weights\n",
    "def SR(index, tickers):\n",
    "\n",
    "    #Slicing the data\n",
    "    Y = Return_Data[index:index+window].drop(columns=['SPY'])\n",
    "\n",
    "    #Filtering based on ticker_list\n",
    "    Y = Y[tickers]\n",
    "     \n",
    "    # Building the portfolio object\n",
    "    port = pf.Portfolio(returns=Y)\n",
    "    # Calculating optimum portfolio\n",
    "\n",
    "    # Select method and estimate input parameters:\n",
    "\n",
    "    method_mu='hist' # Method to estimate expected returns based on historical data.\n",
    "    method_cov='hist' # Method to estimate covariance matrix based on historical data.\n",
    "\n",
    "    port.assets_stats(method_mu=method_mu, method_cov=method_cov, d=0.94)\n",
    "\n",
    "    # Configuring short weights options\n",
    "\n",
    "#     port.sht = True # Allows to use Short Weights\n",
    "#     port.uppersht = 0.3 # Maximum value of sum of short weights in absolute value\n",
    "\n",
    "    # Estimate optimal portfolio:\n",
    "\n",
    "    model='Classic' # Could be Classic (historical), BL (Black Litterman) or FM (Factor Model)\n",
    "    rm = 'MV' # Risk measure used, this time will be variance\n",
    "    obj = 'Sharpe' # Objective function, could be MinRisk, MaxRet, Utility or Sharpe\n",
    "    hist = True # Use historical scenarios for risk measures that depend on scenarios\n",
    "    rf = 0 # Risk free rate\n",
    "    l = 0 # Risk aversion factor, only useful when obj is 'Utility'\n",
    "\n",
    "    w = port.optimization(model=model, rm=rm, obj=obj, rf=rf, l=l, hist=hist)\n",
    "    \n",
    "    df = w.T\n",
    "     \n",
    " \n",
    "    if index+window+month + 1 < len(data):\n",
    "        newdf = pd.DataFrame(np.repeat(df.values,month,axis=0))\n",
    "        newdf.columns = df.columns\n",
    "        newdf['Date'] = data.index.values[index+window+1:index+window+month + 1]\n",
    "    else:\n",
    "        newdf = pd.DataFrame(np.repeat(df.values,len(data)-(index+window+1),axis=0))\n",
    "        newdf.columns = df.columns\n",
    "        newdf['Date'] = data.index.values[index+window+1:len(data)]\n",
    "    \n",
    "    newdf= newdf.set_index('Date')\n",
    "        \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate weights for each portfolio\n",
    "def weights(tickers):\n",
    "    #Computing weights based on COSR/ SR/ 1/n\n",
    "    df_CoSRweights = pd.DataFrame(columns = tickers)\n",
    "    df_SR_weights = pd.DataFrame(columns = tickers)\n",
    "\n",
    "    #Set the value of C\n",
    "#     c = -0.067\n",
    "    c = 0.0\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(Return_Data.index.values)-window:\n",
    "#         print (i)\n",
    "        weight_CoSR = CoSR_weights(i,c, tickers) \n",
    "        df_CoSRweights= df_CoSRweights.append(weight_CoSR)\n",
    "#         tickers = tickers.drop(columns=['SPY'])\n",
    "        weight_SR = SR(i,tickers)\n",
    "        df_SR_weights= df_SR_weights.append(weight_SR)\n",
    "        i = i + month\n",
    "    return df_CoSRweights, df_SR_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_metrics (tickers):\n",
    "    #Individual returns over the period\n",
    "    i_returns = Return_Data[1500:len(data)].drop(columns=['SPY'])\n",
    "    i_returns = i_returns[tickers]\n",
    "\n",
    "    #Calling the weights function\n",
    "\n",
    "    df_CoSRweights, df_SR_weights = weights(tickers)\n",
    "\n",
    "    #Computing SR & equally weighted portfolio returns portfolio returns\n",
    "    p_cosr_returns = df_CoSRweights[tickers[0]]*i_returns[tickers[0]]\n",
    "    p_sr_returns = df_SR_weights[tickers[0]]*i_returns[tickers[0]]\n",
    "    p_ew_returns = (1/len(tickers))*i_returns[tickers[0]]\n",
    "    i=1\n",
    "    while i < len(tickers):\n",
    "        p_cosr_returns = p_cosr_returns + df_CoSRweights[tickers[i]]*i_returns[tickers[i]]\n",
    "        p_sr_returns = p_sr_returns + df_SR_weights[tickers[i]]*i_returns[tickers[i]]\n",
    "        p_ew_returns = p_ew_returns + (1/len(tickers))*i_returns[tickers[i]]\n",
    "        i = i + 1\n",
    "        \n",
    "    #Return-Cumulative returns Dataframe    \n",
    "    df_return = pd.DataFrame({'COSR_Returns': p_cosr_returns, 'SR_Returns': p_sr_returns,\n",
    "                   'EW_Returns': p_ew_returns, 'Cum_COSR_Returns': p_cosr_returns.add(1).cumprod(),\n",
    "                   'Cum_SR_Returns': p_sr_returns.add(1).cumprod(),'Cum_EW_Returns': p_ew_returns.add(1).cumprod(),\n",
    "                  })     \n",
    "        \n",
    "    #Calculatig metrics    \n",
    "    df_metrics = pd.DataFrame(columns=['metric','p_cosr_returns', 'p_sr_returns', 'p_ew_returns'])\n",
    "    metrics= [f for f in dir(qs.stats) if f[0] != '_']\n",
    "    for i in range(0,len(metrics)):\n",
    "        if metrics[i] not in ['compare', 'consecutive_losses', 'consecutive_wins', 'greeks', 'information_ratio', \n",
    "                              'pct_rank', 'r2', 'r_squared', 'rolling_greeks']:\n",
    "            metric = metrics[i]\n",
    "            cosr = eval('qs.stats.'+metrics[i]+'(p_cosr_returns)')\n",
    "            sr = eval('qs.stats.'+metrics[i]+'(p_sr_returns)')\n",
    "            ew = eval('qs.stats.'+metrics[i]+'(p_ew_returns)')\n",
    "            df_metrics = df_metrics.append({'metric':metric, 'p_cosr_returns':cosr, 'p_sr_returns':sr, 'p_ew_returns':ew}, ignore_index=True)\n",
    "\n",
    "    df_metrics= df_metrics.set_index('metric')\n",
    "    \n",
    "    \n",
    "    return df_CoSRweights, df_SR_weights, df_return, df_metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dash dropdown menu\n",
    "options = []\n",
    "for tic in stocks:\n",
    "    #{'label': 'user sees', 'value': 'script sees'}\n",
    "    mydict = {}\n",
    "    mydict['label'] = tic #Apple Co. AAPL\n",
    "    mydict['value'] = tic\n",
    "    options.append(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = html.Div([\n",
    "    html.H1('Portfolio Dashboard', style={'textAlign': 'center'}),\n",
    "    dcc.Markdown(''' --- '''), \n",
    "    html.H1('Systemic Risk Portfolio Analysis'),\n",
    "    html.H3('Enter a stock symbol:', style={'paddingRight': '30px'}),\n",
    "    dcc.Dropdown(id='input-1-state',options = options, multi = True ),\n",
    "    html.Button(id='submit-button-state', n_clicks=0, children='Submit'),\n",
    "    dcc.Graph(id='cum_return'),\n",
    "    dcc.Graph(id='return_metrics'),\n",
    "    dcc.Graph(id='cosr'),\n",
    "    dcc.Graph(id='sr')\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback([ Output('cum_return', 'figure'), Output('return_metrics', 'figure'), \n",
    "               Output('cosr', 'figure'), Output('sr', 'figure')], \n",
    "              [Input('submit-button-state', 'n_clicks')],\n",
    "              [State('input-1-state', 'value')])\n",
    "def update_output(n_clicks, input1):\n",
    "\n",
    "    df_CoSRweights, df_SR_weights, df_return, df_metrics  = return_metrics(input1)\n",
    "\n",
    "#     Cumulative Returns\n",
    "    fig_cum = px.line(df_return, y = ['Cum_COSR_Returns', 'Cum_SR_Returns', 'Cum_EW_Returns'])\n",
    "\n",
    "    fig_cum.update_layout(\n",
    "    title=\"Cumulative returns from \"+str(start)+\" - \"+str(end),\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Weights\",\n",
    "    legend_title=\"Weighting method\")\n",
    "    \n",
    "\n",
    "    \n",
    "    #Metrics\n",
    "    fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=[\"Metrics\",\"COSR Portfolio\", \"SR Portfolio\", \"Equally-Weighted portfolio\"],\n",
    "               fill_color='paleturquoise',\n",
    "                align='left'),\n",
    "    cells=dict(values=[df_metrics.index.values, df_metrics.p_cosr_returns, df_metrics.p_sr_returns, df_metrics.p_ew_returns],\n",
    "               fill_color='lavender',\n",
    "               align='left'))\n",
    "               ])\n",
    "     \n",
    "    \n",
    "    #CoSR Weights\n",
    "    fig_cosr = px.line(df_CoSRweights, y = df_CoSRweights.columns)\n",
    "    fig_cosr.update_layout(\n",
    "    title=\"COSR Weights from \"+str(start)+\"-\"+str(end),\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Weights\",\n",
    "    legend_title=\"Tickers\",\n",
    "    )\n",
    "\n",
    "    #SR Weights\n",
    "    fig_sr = px.line(df_SR_weights, y = df_SR_weights.columns)\n",
    "    fig_sr.update_layout(\n",
    "    title=\"SR Weights from \"+str(start)+\"-\"+str(end),\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Weights\",\n",
    "    legend_title=\"Tickers\",\n",
    "    )\n",
    "    \n",
    "    return fig_cum, fig, fig_cosr, fig_sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " Warning: This is a development server. Do not use app.run_server\n",
      " in production, use a production WSGI server like gunicorn instead.\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [29/Aug/2020 21:16:19] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Aug/2020 21:16:19] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Aug/2020 21:16:19] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "[2020-08-29 21:16:19,740] ERROR in app: Exception on /_dash-update-component [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 2646, in get_loc\n",
      "    return self._engine.get_loc(key)\n",
      "  File \"pandas\\_libs\\index.pyx\", line 111, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: None\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 2292, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1815, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1718, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\flask\\_compat.py\", line 35, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1813, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\flask\\app.py\", line 1799, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 1050, in dispatch\n",
      "    response.set_data(func(*args, outputs_list=outputs_list))\n",
      "  File \"C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\dash\\dash.py\", line 985, in add_context\n",
      "    output_value = func(*args, **kwargs)  # %% callback invoked %%\n",
      "  File \"<ipython-input-17-10b05c1c26dc>\", line 21, in update_output\n",
      "    df_CoSRweights, df_SR_weights, df_return, df_metrics  = return_metrics(input1)\n",
      "  File \"<ipython-input-7-0597dda873a0>\", line 4, in return_metrics\n",
      "    i_returns = i_returns[tickers]\n",
      "  File \"C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 2800, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"C:\\Users\\titas\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 2648, in get_loc\n",
      "    return self._engine.get_loc(self._maybe_cast_indexer(key))\n",
      "  File \"pandas\\_libs\\index.pyx\", line 111, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\index.pyx\", line 138, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: None\n",
      "127.0.0.1 - - [29/Aug/2020 21:16:19] \"POST /_dash-update-component HTTP/1.1\" 500 -\n",
      "127.0.0.1 - - [29/Aug/2020 21:17:14] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
